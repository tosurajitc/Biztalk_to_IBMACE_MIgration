#!/usr/bin/env python3
"""
Program 3:
ACE Module Creator - Program 3 Enhanced
Comprehensive BizTalk to IBM ACE Migration Tool with Intelligent Component Scanning
Replaces llm_logic_enhancer.py with advanced BizTalk root folder scanning and ESQL generation
"""

import os
import json
import xml.etree.ElementTree as ET
from pathlib import Path
from datetime import datetime
from typing import Dict, List, Any, Optional
import re

try:
    from groq import Groq
    from prompt_module import get_esql_creation_prompt, get_enhancement_prompt, get_quality_analysis_prompt
except ImportError as e:
    print(f"Missing dependencies: {e}")
    print("Install with: pip install groq")
    exit(1)

class ACEModuleCreator:
    """
    Comprehensive BizTalk to ACE Migration Tool
    - Scans entire BizTalk root directory
    - Analyzes all BizTalk components  
    - Generates complete ESQL modules
    - Creates Eclipse .project files
    - Produces migration documentation
    """
    
    def __init__(self):
        api_key = os.getenv('GROQ_API_KEY')
        if not api_key:
            raise ValueError("GROQ_API_KEY environment variable required")
        
        self.llm = Groq(api_key=api_key)
        self.generated_files = []
        self.business_context = None
        self.confluence_used = False
        self.biztalk_analysis = None
        
        # Config for compatibility with main.py
        self.config = {
            "groq_settings": {
                "model": "llama3-70b-8192",
                "temperature": 0.1
            }
        }
        
        # File patterns for BizTalk component discovery
        self.file_patterns = {
            'project_files': {
                '.btproj': 'BizTalk Project Files',
                '.sln': 'Solution Files', 
                '.csproj': 'C# Project Files',
                '.snk': 'Strong Name Keys'
            },
            'orchestrations': {
                '.odx': 'Orchestration Files',
                '.odx.cs': 'Orchestration Code-behind'
            },
            'schemas': {
                '.xsd': 'XML Schema Files'
            },
            'maps': {
                '.btm': 'BizTalk Map Files',
                '.btm.cs': 'Map Code-behind'
            },
            'transformations': {
                '.xsl': 'XSLT Transformation Files',
                '.xslt': 'XSLT Transformation Files'
            },
            'custom_code': {
                '.cs': 'C# Source Files'
            },
            'pipeline_components': {
                '.btp': 'Pipeline Files',
                '.btp.cs': 'Pipeline Code-behind'
            },
            'configuration': {
                '.config': 'Configuration Files',
                'BindingInfo.xml': 'Binding Files',
                '.xml': 'XML Configuration Files'
            },
            'assemblies': {
                '.dll': 'Compiled Assemblies'
            }
        }
    
    def load_foundation_structure(self, foundation_dir: str):
        """Load ACE foundation structure - required by main.py"""
        print(f"ðŸ“ Loading ACE foundation: {foundation_dir}")
        return {"foundation_loaded": True}
    
    def enhance_with_groq(self, foundation_dir: str, biztalk_root_dir: str = None, confluence_pdf: str = None, output_dir: str = None):
        """Main enhancement method - required by main.py"""
        print(f"ðŸš€ Starting ACE Module Creator with comprehensive BizTalk scanning")
        
        # DEBUG: Check inputs
        print(f"ðŸ“ DEBUG - Foundation dir: {foundation_dir}")
        print(f"ðŸ” DEBUG - BizTalk root: {biztalk_root_dir}")
        print(f"ðŸ“‹ DEBUG - Confluence PDF: {confluence_pdf is not None}")
        
        return self.enhance(foundation_dir, biztalk_root_dir, confluence_pdf, output_dir)
    
    def enhance(self, foundation_dir: str, biztalk_root_dir: str, confluence_pdf: str = None, output_dir: str = None):
        """
        Main enhancement function with comprehensive BizTalk analysis
        """
        print("ðŸ” Enhanced ACE Module Creation with BizTalk Root Scanning...")
        
        if not output_dir:
            output_dir = os.path.join(foundation_dir, "ace_modules_enhanced")
        
        # 1. Scan BizTalk Root Directory
        print("ðŸ“‚ Phase 1: Scanning BizTalk Root Directory...")
        if not biztalk_root_dir or not os.path.exists(biztalk_root_dir):
            print("âš ï¸ BizTalk root directory not provided or doesn't exist")
            discovered_files = {}
        else:
            discovered_files = self.scan_biztalk_root_folder(biztalk_root_dir)
        
        # 2. Analyze BizTalk Components
        print("ðŸ”¬ Phase 2: Analyzing BizTalk Components...")
        self.biztalk_analysis = self.analyze_biztalk_components(discovered_files, biztalk_root_dir)
        
        # 3. Read MessageFlow from Program 2
        print("ðŸ“Š Phase 3: Reading Generated MessageFlow...")
        messageflow_analysis = self.read_generated_messageflow(foundation_dir)
        
        # 4. Extract Business Context
        if confluence_pdf and os.path.exists(confluence_pdf):
            print("ðŸ“‹ Phase 4: Processing Business Context...")
            self.business_context = self._extract_confluence_context(confluence_pdf)
            self.confluence_used = True
            print(f"âœ… Extracted {len(self.business_context)} characters of business context")
        else:
            print("âš ï¸ No Confluence document provided - using BizTalk analysis only")
            self.confluence_used = False
        
        # 5. Generate Complete ESQL Files
        print("âš¡ Phase 5: Generating Complete ESQL Files...")
        esql_files = self._generate_complete_esql_from_biztalk(
            self.biztalk_analysis, 
            messageflow_analysis, 
            self.business_context, 
            output_dir
        )
        
        # 6. Generate .project file
        print("ðŸ“ Phase 6: Generating Eclipse .project file...")
        mapping_excel_path = r"C:\@Official\@Gen AI\DSV\BizTalk\Analyze_this_folder\GENAI_EPIS_CW1_IN_Document_App\GENAI_ACE\NEW_AI_MH.ESB.EE.Out.DocPackApp\biztalk_ace_mapping.xlsx"
        project_file = self._generate_project_file(self.biztalk_analysis, output_dir, mapping_excel_path)
        
        # 7. Generate Migration Report
        print("ðŸ“‹ Phase 7: Generating Migration Report...")
        migration_report = self._generate_migration_report(self.biztalk_analysis, esql_files, output_dir)
        
        # 8. Save enhancement report
        self._save_enhancement_report(output_dir, esql_files, project_file, migration_report)
        
        print(f"ðŸŽ‰ ACE Module Creation Complete!")
        print(f"ðŸ“ Output: {output_dir}")
        print(f"ðŸ“„ Files generated: {len(self.generated_files)}")
        print(f"ðŸ“‹ Business context used: {'Yes' if self.confluence_used else 'No'}")
        
        return output_dir
    
    def scan_biztalk_root_folder(self, biztalk_root: str) -> Dict:
        """
        Comprehensively scan BizTalk root folder for all relevant files
        """
        print(f"ðŸ” Scanning BizTalk root: {biztalk_root}")
        
        discovered_files = {category: [] for category in self.file_patterns.keys()}
        
        # Recursive scan with depth control (max 8 levels for complex BizTalk structures)
        max_depth = 8
        total_files_scanned = 0
        
        try:
            for root, dirs, files in os.walk(biztalk_root):
                current_depth = root.replace(biztalk_root, '').count(os.sep)
                if current_depth >= max_depth:
                    dirs.clear()
                    continue
                
                # Skip common build/temp directories
                dirs[:] = [d for d in dirs if d not in ['bin', 'obj', '.vs', '.git', '__pycache__']]
                
                for filename in files:
                    total_files_scanned += 1
                    file_path = os.path.join(root, filename)
                    relative_path = os.path.relpath(file_path, biztalk_root)
                    
                    # Check against all patterns
                    for category, patterns in self.file_patterns.items():
                        for pattern, description in patterns.items():
                            if self._matches_pattern(filename, pattern):
                                file_info = {
                                    'path': file_path,
                                    'relative_path': relative_path,
                                    'filename': filename,
                                    'description': description,
                                    'size_kb': round(os.path.getsize(file_path) / 1024, 2),
                                    'modified': datetime.fromtimestamp(os.path.getmtime(file_path)).strftime('%Y-%m-%d %H:%M:%S')
                                }
                                discovered_files[category].append(file_info)
                                break
                        
        except Exception as e:
            print(f"âš ï¸ Error scanning directory: {e}")
        
        # Log discoveries
        print(f"ðŸ“Š Scanned {total_files_scanned} total files")
        for category, files in discovered_files.items():
            if files:
                print(f"  ðŸ“ {category}: {len(files)} files")
        
        return discovered_files
    
    def _matches_pattern(self, filename: str, pattern: str) -> bool:
        """Check if filename matches the pattern"""
        filename_lower = filename.lower()
        pattern_lower = pattern.lower()
        
        if pattern_lower.startswith('.'):
            return filename_lower.endswith(pattern_lower)
        else:
            return pattern_lower in filename_lower
    
    def analyze_biztalk_components(self, discovered_files: Dict, biztalk_root: str) -> Dict:
        """
        Analyze discovered BizTalk components to understand migration requirements
        """
        analysis = {
            'project_structure': {'name': 'UnknownProject', 'references': [], 'compile_items': []},
            'business_processes': [],
            'data_transformations': [],
            'xsl_transformations': [],
            'database_integrations': [],
            'custom_components': [],
            'esql_requirements': [],
            'enrichment_requirements': [],
            'discovery_summary': {
                'total_components': sum(len(files) for files in discovered_files.values()),
                'biztalk_root': biztalk_root,
                'scan_timestamp': datetime.now().isoformat()
            }
        }
        
        # 1. Analyze Project Structure
        if discovered_files.get('project_files'):
            for btproj in discovered_files['project_files']:
                if btproj['filename'].endswith('.btproj'):
                    project_info = self._parse_btproj_file(btproj['path'])
                    analysis['project_structure'] = project_info
                    break
        
        # Extract project name from BizTalk root if not found in .btproj
        if analysis['project_structure']['name'] == 'UnknownProject':
            analysis['project_structure']['name'] = Path(biztalk_root).name
        
        # 2. Analyze Orchestrations
        for orch_file in discovered_files.get('orchestrations', []):
            if orch_file['filename'].endswith('.odx'):
                orch_analysis = self._analyze_orchestration(orch_file['path'])
                analysis['business_processes'].append(orch_analysis)
        
        # 3. Analyze Maps
        for map_file in discovered_files.get('maps', []):
            if map_file['filename'].endswith('.btm'):
                map_analysis = self._analyze_map(map_file['path'])
                analysis['data_transformations'].append(map_analysis)
        
        # 4. Analyze XSL Transformations
        for xsl_file in discovered_files.get('transformations', []):
            if xsl_file['filename'].endswith(('.xsl', '.xslt')):
                xsl_analysis = self._analyze_xsl_transformation(xsl_file['path'])
                analysis['xsl_transformations'].append(xsl_analysis)
        
        # 5. Analyze Custom Code
        for code_file in discovered_files.get('custom_code', []):
            if code_file['filename'].endswith('.cs') and not code_file['filename'].endswith('.Designer.cs'):
                code_analysis = self._analyze_custom_code(code_file['path'])
                analysis['custom_components'].append(code_analysis)
        
        # 6. Generate ESQL Requirements
        analysis['esql_requirements'] = self._determine_esql_requirements(analysis)
        
        # 7. Generate Enrichment Requirements 
        analysis['enrichment_requirements'] = self._determine_enrichment_requirements(analysis)
        
        print(f"âœ… Analysis complete: {analysis['discovery_summary']['total_components']} components analyzed")
        return analysis
    
    def _parse_btproj_file(self, btproj_path: str) -> Dict:
        """Parse .btproj file for project metadata"""
        try:
            tree = ET.parse(btproj_path)
            root = tree.getroot()
            
            project_info = {
                'name': Path(btproj_path).stem,
                'path': btproj_path,
                'references': [],
                'compile_items': [],
                'deployment_settings': {}
            }
            
            # Define namespace
            ns = {'ms': 'http://schemas.microsoft.com/developer/msbuild/2003'}
            
            # Extract references
            for ref in root.findall('.//ms:Reference', ns):
                include = ref.get('Include')
                if include:
                    project_info['references'].append(include)
            
            # Extract compile items
            for compile_item in root.findall('.//ms:Compile', ns):
                include = compile_item.get('Include')
                if include:
                    project_info['compile_items'].append(include)
            
            return project_info
            
        except Exception as e:
            print(f"âš ï¸ Could not parse {btproj_path}: {e}")
            return {
                'name': Path(btproj_path).stem,
                'path': btproj_path,
                'references': [],
                'compile_items': [],
                'error': str(e)
            }
    
    def _analyze_orchestration(self, odx_path: str) -> Dict:
        """Analyze .odx orchestration file"""
        try:
            with open(odx_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            orchestration_info = {
                'name': Path(odx_path).stem,
                'path': odx_path,
                'shapes': [],
                'message_variables': [],
                'port_types': [],
                'business_logic': [],
                'requires_database': False,
                'requires_transformation': False
            }
            
            # Simple text-based analysis (could be enhanced with XML parsing)
            if 'database' in content.lower() or 'sql' in content.lower():
                orchestration_info['requires_database'] = True
            
            if 'transform' in content.lower() or 'map' in content.lower():
                orchestration_info['requires_transformation'] = True
            
            # Extract shape names (simplified)
            shape_patterns = [
                r'<om:Element Type="([^"]+)"',
                r'ShapeName="([^"]+)"'
            ]
            
            for pattern in shape_patterns:
                matches = re.findall(pattern, content)
                orchestration_info['shapes'].extend(matches)
            
            return orchestration_info
            
        except Exception as e:
            return {
                'name': Path(odx_path).stem,
                'path': odx_path,
                'error': str(e),
                'requires_database': False,
                'requires_transformation': False
            }
    
    def _analyze_map(self, btm_path: str) -> Dict:
        """Analyze .btm mapping file"""
        try:
            with open(btm_path, 'rb') as f:
                content = f.read().decode('utf-8', errors='ignore')
            
            map_info = {
                'name': Path(btm_path).stem,
                'path': btm_path,
                'source_schemas': [],
                'target_schemas': [],
                'functoids': [],
                'complexity': 'simple'
            }
            
            # Extract schema references
            schema_pattern = r'Schema="([^"]+)"'
            schemas = re.findall(schema_pattern, content)
            map_info['source_schemas'] = schemas[:len(schemas)//2] if schemas else []
            map_info['target_schemas'] = schemas[len(schemas)//2:] if schemas else []
            
            # Count functoids (complexity indicator)
            functoid_patterns = [
                r'<Functoid',
                r'FunctoidName="([^"]+)"'
            ]
            
            for pattern in functoid_patterns:
                matches = re.findall(pattern, content)
                map_info['functoids'].extend(matches)
            
            # Determine complexity
            if len(map_info['functoids']) > 10:
                map_info['complexity'] = 'complex'
            elif len(map_info['functoids']) > 3:
                map_info['complexity'] = 'medium'
            
            return map_info
            
        except Exception as e:
            return {
                'name': Path(btm_path).stem,
                'path': btm_path,
                'error': str(e),
                'complexity': 'unknown'
            }
    
    def _analyze_custom_code(self, cs_path: str) -> Dict:
        """Analyze .cs custom code file"""
        try:
            with open(cs_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            code_info = {
                'name': Path(cs_path).stem,
                'path': cs_path,
                'classes': [],
                'methods': [],
                'business_logic_detected': False,
                'database_operations': False
            }
            
            # Extract class names
            class_pattern = r'class\s+(\w+)'
            code_info['classes'] = re.findall(class_pattern, content)
            
            # Extract method names
            method_pattern = r'public\s+\w+\s+(\w+)\s*\('
            code_info['methods'] = re.findall(method_pattern, content)
            
            # Detect business logic patterns
            business_logic_indicators = [
                'validation', 'transform', 'process', 'calculate',
                'business', 'rule', 'logic', 'workflow'
            ]
            
            content_lower = content.lower()
            for indicator in business_logic_indicators:
                if indicator in content_lower:
                    code_info['business_logic_detected'] = True
                    break
            
            # Detect database operations
            if any(db_keyword in content_lower for db_keyword in ['sql', 'database', 'connection', 'command']):
                code_info['database_operations'] = True
            
            return code_info
            
        except Exception as e:
            return {
                'name': Path(cs_path).stem,
                'path': cs_path,
                'error': str(e),
                'business_logic_detected': False,
                'database_operations': False
            }
    
    def _analyze_xsl_transformation(self, xsl_path: str) -> Dict:
        """Analyze .xsl/.xslt transformation file"""
        try:
            with open(xsl_path, 'r', encoding='utf-8') as f:
                content = f.read()
            
            xsl_info = {
                'name': Path(xsl_path).stem,
                'path': xsl_path,
                'templates': [],
                'parameters': [],
                'imports': [],
                'complexity': 'simple',
                'transformation_type': 'standard'
            }
            
            # Extract template names
            template_pattern = r'<xsl:template[^>]*name="([^"]+)"'
            xsl_info['templates'] = re.findall(template_pattern, content)
            
            # Extract parameters
            param_pattern = r'<xsl:param[^>]*name="([^"]+)"'
            xsl_info['parameters'] = re.findall(param_pattern, content)
            
            # Extract imports/includes
            import_pattern = r'<xsl:(?:import|include)[^>]*href="([^"]+)"'
            xsl_info['imports'] = re.findall(import_pattern, content)
            
            # Determine complexity
            if len(xsl_info['templates']) > 10 or 'for-each' in content.lower():
                xsl_info['complexity'] = 'complex'
            elif len(xsl_info['templates']) > 3 or 'choose' in content.lower():
                xsl_info['complexity'] = 'medium'
            
            # Determine transformation type
            if 'database' in content.lower() or 'lookup' in content.lower():
                xsl_info['transformation_type'] = 'enrichment'
            elif 'universal' in content.lower() or 'event' in content.lower():
                xsl_info['transformation_type'] = 'business_event'
            
            return xsl_info
            
        except Exception as e:
            return {
                'name': Path(xsl_path).stem,
                'path': xsl_path,
                'error': str(e),
                'complexity': 'unknown',
                'transformation_type': 'unknown'
            }
    
    def read_generated_messageflow(self, foundation_dir: str) -> Dict:
        """Read messageflow XML generated by Program 2"""
        messageflow_analysis = {
            'flows': [],
            'nodes': [],
            'connections': [],
            'compute_modules': []
        }
        
        try:
            # Look for messageflow files in the foundation directory
            flows_dir = os.path.join(foundation_dir, 'flows')
            if os.path.exists(flows_dir):
                for msgflow_file in Path(flows_dir).glob('*.msgflow'):
                    flow_info = self._parse_messageflow(str(msgflow_file))
                    messageflow_analysis['flows'].append(flow_info)
            
            print(f"ðŸ“Š Found {len(messageflow_analysis['flows'])} message flows")
            
        except Exception as e:
            print(f"âš ï¸ Could not read message flows: {e}")
        
        return messageflow_analysis
    
    def _parse_messageflow(self, msgflow_path: str) -> Dict:
        """Parse messageflow XML file"""
        try:
            tree = ET.parse(msgflow_path)
            root = tree.getroot()
            
            flow_info = {
                'name': Path(msgflow_path).stem,
                'path': msgflow_path,
                'nodes': [],
                'connections': []
            }
            
            # Extract nodes
            for node in root.iter():
                if 'Node' in node.tag:
                    node_info = {
                        'type': node.tag,
                        'name': node.get('name', ''),
                        'properties': dict(node.attrib)
                    }
                    flow_info['nodes'].append(node_info)
            
            return flow_info
            
        except Exception as e:
            return {
                'name': Path(msgflow_path).stem,
                'path': msgflow_path,
                'error': str(e)
            }
    
    def _determine_esql_requirements(self, biztalk_analysis: Dict) -> List[Dict]:
        """Determine ESQL modules needed based on BizTalk analysis"""
        esql_requirements = []
        project_name = biztalk_analysis['project_structure']['name']
        
        # Always generate core modules
        core_modules = [
            {
                'type': 'main_processing',
                'name': f"{project_name}_Main",
                'purpose': 'Primary message processing logic',
                'priority': 1,
                'source_component': 'System Generated'
            },
            {
                'type': 'validation',
                'name': f"{project_name}_Validation",
                'purpose': 'Input/output message validation',
                'priority': 1,
                'source_component': 'System Generated'
            },
            {
                'type': 'error_handling',
                'name': f"{project_name}_ErrorHandling",
                'purpose': 'Error processing and logging',
                'priority': 1,
                'source_component': 'System Generated'
            }
        ]
        
        esql_requirements.extend(core_modules)
        
        # Based on Orchestrations
        for process in biztalk_analysis['business_processes']:
            if process.get('requires_database'):
                esql_requirements.append({
                    'type': 'database_operations',
                    'name': f"{project_name}_DatabaseOps",
                    'purpose': 'Database enrichment and lookups',
                    'priority': 2,
                    'source_component': process['path']
                })
            
            if process.get('requires_transformation'):
                esql_requirements.append({
                    'type': 'transformation',
                    'name': f"{project_name}_Transformation",
                    'purpose': 'Message transformation logic',
                    'priority': 2,
                    'source_component': process['path']
                })
        
        # Based on Maps
        for transformation in biztalk_analysis['data_transformations']:
            esql_requirements.append({
                'type': 'map_conversion',
                'name': f"{transformation['name']}_Transform",
                'purpose': f"Converted from BizTalk map: {transformation['name']}",
                'priority': 2,
                'source_component': transformation['path'],
                'complexity': transformation.get('complexity', 'simple')
            })
        
        # Based on Custom Code with Business Logic
        for custom_comp in biztalk_analysis['custom_components']:
            if custom_comp.get('business_logic_detected'):
                esql_requirements.append({
                    'type': 'business_logic',
                    'name': f"{custom_comp['name']}_BusinessLogic",
                    'purpose': f"Custom business logic from: {custom_comp['name']}",
                    'priority': 3,
                    'source_component': custom_comp['path']
                })
        
        # Remove duplicates and sort by priority
        unique_requirements = []
        seen_names = set()
        
        for req in sorted(esql_requirements, key=lambda x: x['priority']):
            if req['name'] not in seen_names:
                unique_requirements.append(req)
                seen_names.add(req['name'])
        
        return unique_requirements
    
    def _determine_enrichment_requirements(self, biztalk_analysis: Dict) -> List[Dict]:
        """Determine enrichment files needed based on BizTalk analysis"""
        enrichment_requirements = []
        project_name = biztalk_analysis['project_structure']['name']
        
        # Standard enrichment modules based on business context patterns
        standard_enrichments = [
            {
                'type': 'company_code_lookup',
                'name': f"{project_name}_CompanyCodeLookup",
                'purpose': 'Company code resolution and validation',
                'priority': 2,
                'database_required': True
            },
            {
                'type': 'shipment_enrichment', 
                'name': f"{project_name}_ShipmentEnrichment",
                'purpose': 'Shipment data lookup by SSN and house bill',
                'priority': 2,
                'database_required': True
            },
            {
                'type': 'document_validation',
                'name': f"{project_name}_DocumentValidation",
                'purpose': 'Document type validation and publishing checks',
                'priority': 2,
                'database_required': True
            },
            {
                'type': 'customs_brokerage',
                'name': f"{project_name}_CustomsBrokerage", 
                'purpose': 'Customs brokerage data enrichment',
                'priority': 3,
                'database_required': True
            },
            {
                'type': 'eadapter_recipient',
                'name': f"{project_name}_EAdapterRecipient",
                'purpose': 'eAdapter recipient determination and routing',
                'priority': 2,
                'database_required': True
            }
        ]
        
        # Add enrichments based on discovered components
        for process in biztalk_analysis['business_processes']:
            if process.get('requires_database'):
                enrichment_requirements.extend(standard_enrichments)
                break
        
        # Add enrichments based on XSL transformations that require enrichment
        for xsl_transform in biztalk_analysis.get('xsl_transformations', []):
            if xsl_transform.get('transformation_type') == 'enrichment':
                enrichment_requirements.append({
                    'type': 'xsl_data_enrichment',
                    'name': f"{xsl_transform['name']}_DataEnrichment",
                    'purpose': f"Data enrichment for XSL transformation: {xsl_transform['name']}",
                    'priority': 2,
                    'database_required': True,
                    'source_xsl': xsl_transform['path']
                })
        
        # Remove duplicates
        unique_enrichments = []
        seen_names = set()
        
        for req in sorted(enrichment_requirements, key=lambda x: x['priority']):
            if req['name'] not in seen_names:
                unique_enrichments.append(req)
                seen_names.add(req['name'])
        
        return unique_enrichments
    
    def _generate_complete_esql_from_biztalk(self, biztalk_analysis: Dict, messageflow_analysis: Dict, 
                                           business_context: str, output_dir: str) -> List[str]:
        """Generate complete ESQL files, XSL files, and enrichment files based on BizTalk analysis"""
        
        esql_output_dir = os.path.join(output_dir, "esql")
        modules_dir = os.path.join(esql_output_dir, "modules")
        functions_dir = os.path.join(esql_output_dir, "functions")
        procedures_dir = os.path.join(esql_output_dir, "procedures")
        enrichment_dir = os.path.join(esql_output_dir, "enrichment")
        
        # XSL and transformations
        transforms_dir = os.path.join(output_dir, "transforms")
        xsl_dir = os.path.join(transforms_dir, "xsl")
        
        # Create all directories
        for dir_path in [modules_dir, functions_dir, procedures_dir, enrichment_dir, xsl_dir]:
            os.makedirs(dir_path, exist_ok=True)
        
        generated_files = []
        
        # 1. Generate ESQL modules for each requirement
        for requirement in biztalk_analysis['esql_requirements']:
            print(f"  âš¡ Generating {requirement['name']}.esql...")
            
            esql_content = self._generate_esql_with_llm_using_prompt_module(
                requirement,
                biztalk_analysis,
                business_context,
                messageflow_analysis
            )
            
            if esql_content:
                # Determine output directory based on type
                if requirement['type'] in ['main_processing', 'validation', 'error_handling']:
                    target_dir = modules_dir
                elif requirement['type'] in ['business_logic', 'transformation', 'map_conversion']:
                    target_dir = modules_dir
                else:
                    target_dir = procedures_dir
                
                file_path = os.path.join(target_dir, f"{requirement['name']}.esql")
                self._save_file(file_path, esql_content)
                generated_files.append(file_path)
        
        # 2. Generate enrichment ESQL files
        for enrichment in biztalk_analysis.get('enrichment_requirements', []):
            print(f"  ðŸ” Generating enrichment {enrichment['name']}.esql...")
            
            enrichment_content = self._generate_enrichment_esql(
                enrichment,
                biztalk_analysis,
                business_context
            )
            
            if enrichment_content:
                file_path = os.path.join(enrichment_dir, f"{enrichment['name']}.esql")
                self._save_file(file_path, enrichment_content)
                generated_files.append(file_path)
        
        # 3. Generate XSL transformation files
        for xsl_transform in biztalk_analysis.get('xsl_transformations', []):
            print(f"  ðŸ”„ Generating XSL transformation {xsl_transform['name']}.xsl...")
            
            xsl_content = self._generate_xsl_transformation(
                xsl_transform,
                biztalk_analysis,
                business_context
            )
            
            if xsl_content:
                file_path = os.path.join(xsl_dir, f"{xsl_transform['name']}_ACE.xsl")
                self._save_file(file_path, xsl_content)
                generated_files.append(file_path)
        
        # 4. Generate additional XSL files for complex transformations
        if biztalk_analysis['data_transformations'] and not biztalk_analysis.get('xsl_transformations'):
            # Generate XSL files for BizTalk maps that don't have explicit XSL
            for map_transform in biztalk_analysis['data_transformations']:
                if map_transform.get('complexity') in ['medium', 'complex']:
                    print(f"  ðŸ”„ Generating XSL for map {map_transform['name']}.xsl...")
                    
                    xsl_content = self._generate_xsl_from_map(
                        map_transform,
                        biztalk_analysis,
                        business_context
                    )
                    
                    if xsl_content:
                        file_path = os.path.join(xsl_dir, f"{map_transform['name']}_Transform.xsl")
                        self._save_file(file_path, xsl_content)
                        generated_files.append(file_path)
        
        return generated_files
    
    def _generate_esql_with_llm_using_prompt_module(self, requirement: Dict, biztalk_analysis: Dict, 
                                                   business_context: str, messageflow_analysis: Dict) -> str:
        """Generate ESQL content using LLM with prompt_module.py integration"""
        
        try:
            # Create additional context for prompt_module
            additional_context = {
                'biztalk_source': requirement.get('source_component', 'Unknown'),
                'component_type': requirement.get('type', 'Unknown'),
                'target_ace_library': 'ESQL Module',
                'project_structure': biztalk_analysis['project_structure'],
                'message_flows': messageflow_analysis.get('flows', []),
                'complexity': requirement.get('complexity', 'standard')
            }
            
            # Use prompt_module.py function for ESQL creation
            prompt = get_esql_creation_prompt(
                module_name=requirement['name'],
                purpose=requirement['purpose'],
                business_context=business_context,
                additional_context=additional_context
            )
            
            # Add specific enhancement based on type using prompt_module
            if requirement['type'] in ['database_operations', 'business_logic', 'error_handling']:
                enhancement_prompt = get_enhancement_prompt(
                    original_esql="",  # For new modules
                    enhancement_type=requirement['type'],
                    context=additional_context
                )
                prompt += f"\n\n## ADDITIONAL ENHANCEMENT REQUIREMENTS:\n{enhancement_prompt}"
            
            response = self.llm.chat.completions.create(
                model=self.config["groq_settings"]["model"],
                messages=[
                    {
                        "role": "system", 
                        "content": "You are an expert IBM ACE developer specializing in BizTalk to ACE migrations. Generate production-ready ESQL code with proper error handling, performance optimization, and business logic integration. Follow all ESQL coding standards strictly."
                    },
                    {"role": "user", "content": prompt}
                ],
                temperature=self.config["groq_settings"]["temperature"],
                max_tokens=3000
            )
            
            esql_content = response.choices[0].message.content
            
            # Quality check using prompt_module
            ENABLE_QUALITY_ANALYSIS = False

            if ENABLE_QUALITY_ANALYSIS:
                try:
                    quality_prompt = get_quality_analysis_prompt(esql_content)
                    quality_response = self.llm.chat.completions.create(
                        model=self.config["groq_settings"]["model"],
                        messages=[
                            {"role": "system", "content": "You are an ESQL code quality analyst."},
                            {"role": "user", "content": quality_prompt}
                        ],
                        temperature=0.1,
                        max_tokens=1000
                    )
                    
                    print(f"  ðŸ“Š Quality analysis: {quality_response.choices[0].message.content[:100]}...")
                    
                except Exception as quality_error:
                    print(f"  âš ï¸ Quality check failed: {quality_error}")
            
            return esql_content
            
        except Exception as e:
            print(f"âš ï¸ Error generating ESQL for {requirement['name']}: {e}")
            return self._generate_fallback_esql(requirement)
    
    def _generate_fallback_esql(self, requirement: Dict) -> str:
        """Generate basic fallback ESQL if LLM fails"""
        module_name = requirement['name']
        
        return f"""-- {module_name}.esql
-- Generated by ACE Module Creator
-- Purpose: {requirement['purpose']}
-- Source: {requirement.get('source_component', 'System Generated')}

CREATE COMPUTE MODULE {module_name}_Compute
    CREATE FUNCTION Main() RETURNS BOOLEAN
    BEGIN
        -- Copy input to output
        SET OutputRoot = InputRoot;
        
        -- Generate new correlation ID
        SET OutputRoot.MQMD.MsgId = UUIDASBLOB();
        SET OutputRoot.MQMD.CorrelId = InputRoot.MQMD.MsgId;
        
        -- Add basic processing logic here
        -- TODO: Implement specific business logic for {requirement['type']}
        
        -- Log processing
        SET Environment.Variables.ProcessingTimestamp = CURRENT_TIMESTAMP;
        SET Environment.Variables.ModuleName = '{module_name}';
        
        RETURN TRUE;
    END;
    
    CREATE FUNCTION ValidateInput() RETURNS BOOLEAN
    BEGIN
        -- Basic validation
        IF InputRoot IS NULL THEN
            SET Environment.Variables.ValidationError = 'Input message is null';
            RETURN FALSE;
        END IF;
        
        RETURN TRUE;
    END;
END MODULE;
"""
    
    def _generate_enrichment_esql(self, enrichment: Dict, biztalk_analysis: Dict, business_context: str) -> str:
        """Generate enrichment ESQL files using prompt_module.py"""
        
        try:
            # Create enrichment-specific context
            enrichment_context = {
                'enrichment_type': enrichment['type'],
                'database_required': enrichment.get('database_required', True),
                'project_name': biztalk_analysis['project_structure']['name'],
                'business_processes': len(biztalk_analysis['business_processes']),
                'source_xsl': enrichment.get('source_xsl', '')
            }
            
            # Use get_esql_creation_prompt for enrichment modules
            from prompt_module import get_esql_creation_prompt
            
            prompt = get_esql_creation_prompt(
                module_name=enrichment['name'],
                purpose=enrichment['purpose'],
                business_context=business_context,
                additional_context=enrichment_context
            )
            
            # Add enrichment-specific requirements
            enrichment_prompt_addition = f"""

## ENRICHMENT-SPECIFIC REQUIREMENTS:

### {enrichment['type'].upper()} ENRICHMENT PATTERN:
"""
            
            if enrichment['type'] == 'company_code_lookup':
                enrichment_prompt_addition += """
- Implement conditional company code resolution
- Handle empty company codes with country-based fallback
- Use parameterized database queries
- Include proper error handling for lookup failures

### DATABASE OPERATION PATTERN:
```
IF COALESCE(InputCompanyCode,'') = '' THEN
    CALL sp_GetMainCompanyInCountry(CountryCode) INTO OutputCompanyCode;
ELSE
    SET OutputCompanyCode = InputCompanyCode;
END IF;
```
"""
            
            elif enrichment['type'] == 'shipment_enrichment':
                enrichment_prompt_addition += """
- Implement conditional shipment lookup by SSN
- Handle entity type validation (SHP, QBK)
- Include house bill lookup as fallback
- Store enrichment results in Environment variables

### CONDITIONAL LOOKUP PATTERN:
```
IF EntityType IN ('SHP', 'QBK') AND COALESCE(SSN,'') <> '' THEN
    CALL GetShipmentBySSN(SSN, SID, STP) INTO ShipmentId, IsBooking;
    SET Environment.EE_ShipmentId = ShipmentId;
END IF;
```
"""
            
            elif enrichment['type'] == 'eadapter_recipient':
                enrichment_prompt_addition += """
- Determine eAdapter recipient based on environment and country
- Handle production vs development environment routing
- Include recipient validation and error handling

### RECIPIENT DETERMINATION PATTERN:
```
SET RecipientId = CASE GetESBEnvironment() 
    WHEN 'Production' THEN CountryCode || 'PRD'
    ELSE CountryCode || 'DQA'
END;
```
"""
            
            full_prompt = prompt + enrichment_prompt_addition
            
            response = self.llm.chat.completions.create(
                model=self.config["groq_settings"]["model"],
                messages=[
                    {
                        "role": "system",
                        "content": "You are an expert IBM ACE developer specializing in database enrichment patterns and BizTalk to ACE migrations. Generate production-ready ESQL enrichment modules with proper database operations, error handling, and performance optimization."
                    },
                    {"role": "user", "content": full_prompt}
                ],
                temperature=self.config["groq_settings"]["temperature"],
                max_tokens=3000
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            print(f"âš ï¸ Error generating enrichment ESQL for {enrichment['name']}: {e}")
            return self._generate_fallback_enrichment_esql(enrichment)
    
    def _generate_fallback_enrichment_esql(self, enrichment: Dict) -> str:
        """Generate fallback enrichment ESQL if LLM fails"""
        module_name = enrichment['name']
        
        return f"""-- {module_name}.esql
-- Generated by ACE Module Creator - Enrichment Module
-- Purpose: {enrichment['purpose']}
-- Type: {enrichment['type']}

CREATE COMPUTE MODULE {module_name}_Compute
    CREATE FUNCTION Main() RETURNS BOOLEAN
    BEGIN
        -- Copy input to output
        SET OutputRoot = InputRoot;
        
        -- Database enrichment logic placeholder
        DECLARE EXIT HANDLER FOR SQLEXCEPTION
        BEGIN
            SET Environment.Variables.EnrichmentError = SQLERRORTEXT;
            SET Environment.Variables.ErrorModule = '{module_name}';
            RETURN FALSE;
        END;
        
        -- TODO: Implement specific enrichment logic for {enrichment['type']}
        -- Add database lookup operations here
        
        -- Log enrichment activity
        SET Environment.Variables.EnrichmentTimestamp = CURRENT_TIMESTAMP;
        SET Environment.Variables.EnrichmentModule = '{module_name}';
        
        RETURN TRUE;
    END;
END MODULE;
"""
    
    def _generate_xsl_transformation(self, xsl_transform: Dict, biztalk_analysis: Dict, business_context: str) -> str:
        """Generate XSL transformation files"""
        
        try:
            # Create XSL-specific prompt using business context
            xsl_prompt = f"""# XSL Transformation Generation

Generate a production-ready XSL transformation file for IBM ACE based on BizTalk analysis.

## XSL TRANSFORMATION DETAILS:
- **Name**: {xsl_transform['name']}
- **Source Path**: {xsl_transform.get('path', 'Unknown')}
- **Complexity**: {xsl_transform.get('complexity', 'simple')}
- **Transformation Type**: {xsl_transform.get('transformation_type', 'standard')}
- **Templates Found**: {len(xsl_transform.get('templates', []))}

## BUSINESS CONTEXT:
{business_context[:1000] if business_context else 'Standard transformation requirements'}

## XSL REQUIREMENTS:

### 1. XML Structure:
- Valid XSLT 1.0 or 2.0 syntax
- Proper namespace declarations
- Compatible with IBM ACE XSLTransform node

### 2. Transformation Logic:
"""
            
            if xsl_transform.get('transformation_type') == 'business_event':
                xsl_prompt += """
- Convert CDM document format to Universal Event format
- Include proper message routing and correlation
- Add timestamp and tracking information
- Handle CargoWise One specific fields
"""
            elif xsl_transform.get('transformation_type') == 'enrichment':
                xsl_prompt += """
- Incorporate enriched data from database lookups
- Handle conditional field mapping based on enrichment results
- Include fallback values for missing enrichment data
"""
            else:
                xsl_prompt += """
- Standard field-to-field transformation
- Handle missing or null values appropriately
- Maintain data type compatibility
"""
            
            xsl_prompt += f"""

### 3. Template Structure:
Generate templates for the following patterns:
{', '.join(xsl_transform.get('templates', ['root', 'identity', 'default']))}

### 4. Parameters and Variables:
Include support for:
{', '.join(xsl_transform.get('parameters', ['source-system', 'timestamp', 'correlation-id']))}

## OUTPUT REQUIREMENTS:
Generate complete, valid XSL transformation file that can be used directly in ACE XSLTransform node.

## XSL TRANSFORMATION:
"""
            
            response = self.llm.chat.completions.create(
                model=self.config["groq_settings"]["model"],
                messages=[
                    {
                        "role": "system",
                        "content": "You are an expert XSLT developer specializing in IBM ACE transformations and BizTalk to ACE migrations. Generate production-ready XSL transformation files with proper XML structure, namespace handling, and business logic integration."
                    },
                    {"role": "user", "content": xsl_prompt}
                ],
                temperature=self.config["groq_settings"]["temperature"],
                max_tokens=3000
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            print(f"âš ï¸ Error generating XSL transformation for {xsl_transform['name']}: {e}")
            return self._generate_fallback_xsl(xsl_transform)
    
    def _generate_xsl_from_map(self, map_transform: Dict, biztalk_analysis: Dict, business_context: str) -> str:
        """Generate XSL transformation from BizTalk map analysis"""
        
        try:
            map_prompt = f"""# XSL Generation from BizTalk Map

Generate XSL transformation file from BizTalk map analysis.

## BIZTALK MAP DETAILS:
- **Map Name**: {map_transform['name']}
- **Complexity**: {map_transform.get('complexity', 'simple')}
- **Functoids**: {len(map_transform.get('functoids', []))}
- **Source Schemas**: {', '.join(map_transform.get('source_schemas', ['Unknown']))}
- **Target Schemas**: {', '.join(map_transform.get('target_schemas', ['Unknown']))}

## BUSINESS CONTEXT:
{business_context[:500] if business_context else 'Standard map conversion requirements'}

## CONVERSION REQUIREMENTS:

### 1. Map Logic Conversion:
- Convert BizTalk functoid logic to XSL equivalent operations
- Handle field mappings and data transformations
- Include conditional logic and value mappings

### 2. Schema Handling:
- Map source schema elements to target schema structure
- Handle namespace transformations if required
- Maintain data type compatibility

### 3. Functoid Conversion Patterns:
"""
            
            if map_transform.get('functoids'):
                map_prompt += f"- Convert {len(map_transform['functoids'])} functoids to XSL operations\n"
                map_prompt += "- Include string manipulation, mathematical, and logical operations\n"
            
            map_prompt += """

## OUTPUT REQUIREMENTS:
Generate complete XSL transformation that replicates the BizTalk map functionality.

## XSL TRANSFORMATION:
"""
            
            response = self.llm.chat.completions.create(
                model=self.config["groq_settings"]["model"],
                messages=[
                    {
                        "role": "system",
                        "content": "You are an expert in BizTalk to ACE migrations specializing in converting BizTalk maps to XSL transformations. Generate production-ready XSL files that replicate BizTalk map functionality using proper XSLT patterns."
                    },
                    {"role": "user", "content": map_prompt}
                ],
                temperature=self.config["groq_settings"]["temperature"],
                max_tokens=3000
            )
            
            return response.choices[0].message.content
            
        except Exception as e:
            print(f"âš ï¸ Error generating XSL from map for {map_transform['name']}: {e}")
            return self._generate_fallback_xsl({'name': map_transform['name']})
    
    def _generate_fallback_xsl(self, xsl_info: Dict) -> str:
        """Generate basic fallback XSL if LLM fails"""
        xsl_name = xsl_info['name']
        
        return f"""<?xml version="1.0" encoding="UTF-8"?>
<xsl:stylesheet version="1.0" xmlns:xsl="http://www.w3.org/1999/XSL/Transform">
    
    <!-- Generated by ACE Module Creator -->
    <!-- XSL Transformation: {xsl_name} -->
    <!-- Purpose: Data transformation for IBM ACE -->
    
    <xsl:output method="xml" indent="yes" encoding="UTF-8"/>
    
    <!-- Identity transformation template -->
    <xsl:template match="@*|node()">
        <xsl:copy>
            <xsl:apply-templates select="@*|node()"/>
        </xsl:copy>
    </xsl:template>
    
    <!-- Root template -->
    <xsl:template match="/">
        <xsl:apply-templates/>
    </xsl:template>
    
    <!-- TODO: Add specific transformation templates for {xsl_name} -->
    <!-- Add field mappings, conditional logic, and data transformations here -->
    
</xsl:stylesheet>
"""
    
    def _generate_project_file(self, biztalk_analysis: Dict, output_dir: str, mapping_excel_path: str = None) -> str:
        """
        Generate Eclipse .project file for ACE toolkit integration
        Uses simple template with required ACE libraries from mapping Excel file
        """
        
        project_name = biztalk_analysis['project_structure']['name']
        
        # Extract ACE library dependencies from mapping Excel file
        ace_libraries = self._extract_ace_libraries_from_mapping(mapping_excel_path)
        
        # Generate project dependencies XML (one <project> tag per library)
        project_dependencies = ""
        if ace_libraries:
            project_dependencies = "\n".join([f"\t\t<project>{lib}</project>" for lib in ace_libraries])
        
        # Use the simple template structure
        project_content = f"""<?xml version="1.0" encoding="UTF-8"?>
    <projectDescription>
    \t<name>{project_name}</name>
    \t<projects>
    {project_dependencies}
    \t</projects>
    \t<buildSpec>
    \t\t<buildCommand>
    \t\t\t<name>com.ibm.etools.mft.flow.msgflowbuilder</name>
    \t\t\t<arguments>
    \t\t\t</arguments>
    \t\t</buildCommand>
    \t</buildSpec>
    \t<natures>
    \t\t<nature>com.ibm.etools.msgbroker.tooling.applicationNature</nature>
    \t\t<nature>com.ibm.etools.msgbroker.tooling.messageBrokerProjectNature</nature>
    \t</natures>
    </projectDescription>"""
        
        project_file_path = os.path.join(output_dir, ".project")
        self._save_file(project_file_path, project_content)
        
        print(f"âœ… Simple .project file created with {len(ace_libraries)} ACE library dependencies")
        return project_file_path

    def _extract_ace_libraries_from_mapping(self, mapping_excel_path: str = None) -> List[str]:
        """
        Extract required ACE libraries from the mapping Excel file
        Returns list of ACE library names for project dependencies
        """
        ace_libraries = []
        
        if not mapping_excel_path or not os.path.exists(mapping_excel_path):
            print("âŒ Mapping Excel file required for library dependencies")
            raise FileNotFoundError(f"Mapping Excel file not found: {mapping_excel_path}")
        
        try:
            print(f"ðŸ“Š Reading ACE libraries from: {mapping_excel_path}")
            
            # Import pandas 
            try:
                import pandas as pd
            except ImportError:
                print("âŒ pandas required for reading mapping Excel")
                raise ImportError("Please install pandas: pip install pandas")
            
            # Read Component Mapping sheet (note: space not underscore)
            df = pd.read_excel(mapping_excel_path, sheet_name="Component Mapping")
            
            # Extract libraries from required_ace_library column 
            if 'required_ace_library' in df.columns:
                ace_components = df['required_ace_library'].dropna().unique()
                
                for component in ace_components:
                    if isinstance(component, str) and component.strip():
                        # Filter out "None of the above" and similar non-library entries
                        if 'none of the above' not in component.lower() and '_Lib' in component:
                            lib_name = component.strip()
                            if lib_name and lib_name not in ace_libraries:
                                ace_libraries.append(lib_name)
            
            # If no libraries found, that's an issue with the mapping file
            if not ace_libraries:
                raise ValueError("No ACE libraries found in Component_Mapping sheet")
                
        except Exception as e:
            print(f"âŒ Error reading mapping file: {e}")
            raise
        
        print(f"ðŸ“š Found {len(ace_libraries)} ACE libraries: {ace_libraries}")
        return ace_libraries

    
    def _generate_migration_report(self, biztalk_analysis: Dict, esql_files: List[str], output_dir: str) -> str:
        """Generate comprehensive migration report"""
        
        project_name = biztalk_analysis['project_structure']['name']
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        report_content = f"""# BizTalk to ACE Migration Report
**Project**: {project_name}  
**Generated**: {timestamp}  
**Tool**: ACE Module Creator v1.0

## Migration Summary

### Source Analysis
- **BizTalk Root**: {biztalk_analysis['discovery_summary']['biztalk_root']}
- **Total Components Found**: {biztalk_analysis['discovery_summary']['total_components']}
- **Business Processes**: {len(biztalk_analysis['business_processes'])}
- **Data Transformations**: {len(biztalk_analysis['data_transformations'])}
- **Custom Components**: {len(biztalk_analysis['custom_components'])}

### Generated ACE Artifacts
- **ESQL Modules**: {len([f for f in esql_files if f.endswith('.esql')])}
- **XSL Transformations**: {len([f for f in esql_files if f.endswith('.xsl')])}
- **Enrichment Files**: {len(biztalk_analysis.get('enrichment_requirements', []))}
- **Project Files**: 1 (.project)
- **Business Context Used**: {"Yes" if self.confluence_used else "No"}

## ESQL Modules Generated

"""
        
        # List generated ESQL modules
        for i, esql_file in enumerate(esql_files, 1):
            module_name = Path(esql_file).stem
            relative_path = os.path.relpath(esql_file, output_dir)
            file_type = "XSL Transform" if esql_file.endswith('.xsl') else \
                       "Enrichment" if "enrichment" in relative_path else \
                       "ESQL Module"
            report_content += f"{i}. **{module_name}** ({file_type})\n   - Path: `{relative_path}`\n   - Size: {round(os.path.getsize(esql_file)/1024, 2)} KB\n\n"
        
        # BizTalk Components Analysis
        report_content += """## BizTalk Components Analysis

### Business Processes (Orchestrations)
"""
        
        if biztalk_analysis['business_processes']:
            for process in biztalk_analysis['business_processes']:
                report_content += f"- **{process['name']}**\n"
                report_content += f"  - Path: `{process.get('path', 'Unknown')}`\n"
                report_content += f"  - Requires Database: {process.get('requires_database', False)}\n"
                report_content += f"  - Requires Transformation: {process.get('requires_transformation', False)}\n\n"
        else:
            report_content += "- No orchestrations found\n\n"
        
        report_content += """### Data Transformations (Maps)
"""
        
        if biztalk_analysis['data_transformations']:
            for transform in biztalk_analysis['data_transformations']:
                report_content += f"- **{transform['name']}**\n"
                report_content += f"  - Complexity: {transform.get('complexity', 'Unknown')}\n"
                report_content += f"  - Functoids: {len(transform.get('functoids', []))}\n"
                report_content += f"  - Source Schemas: {', '.join(transform.get('source_schemas', ['None']))}\n\n"
        else:
            report_content += "- No maps found\n\n"
        
        report_content += """### XSL Transformations
"""
        
        if biztalk_analysis.get('xsl_transformations'):
            for xsl_transform in biztalk_analysis['xsl_transformations']:
                report_content += f"- **{xsl_transform['name']}**\n"
                report_content += f"  - Complexity: {xsl_transform.get('complexity', 'Unknown')}\n"
                report_content += f"  - Transformation Type: {xsl_transform.get('transformation_type', 'standard')}\n"
                report_content += f"  - Templates: {len(xsl_transform.get('templates', []))}\n\n"
        else:
            report_content += "- No XSL transformations found\n\n"
        
        report_content += """### Enrichment Requirements
"""
        
        if biztalk_analysis.get('enrichment_requirements'):
            for enrichment in biztalk_analysis['enrichment_requirements']:
                report_content += f"- **{enrichment['name']}**\n"
                report_content += f"  - Type: {enrichment.get('type', 'Unknown')}\n"
                report_content += f"  - Database Required: {enrichment.get('database_required', False)}\n"
                report_content += f"  - Priority: {enrichment.get('priority', 'Unknown')}\n\n"
        else:
            report_content += "- No specific enrichment requirements identified\n\n"
        
        # Migration recommendations
        report_content += """## Migration Recommendations

### Next Steps
1. **Review Generated ESQL**: Examine each generated ESQL module for business logic accuracy
2. **Test Message Flows**: Create test cases for each message flow scenario
3. **Database Configuration**: Set up database connections and test lookup procedures
4. **Business Logic Validation**: Validate transformed business rules against original BizTalk logic
5. **Performance Testing**: Test message throughput and transformation performance

### Known Limitations
- Complex BizTalk functoids may require manual review and adjustment
- Custom .NET assemblies need manual conversion to Java compute nodes
- Pipeline components require custom ACE node development
- Some BizTalk-specific features may not have direct ACE equivalents

### Deployment Checklist
- [ ] Import project into ACE Toolkit
- [ ] Configure database connections
- [ ] Test all message flows
- [ ] Validate business logic
- [ ] Performance test with production data volumes
- [ ] Deploy to integration server

## Generated File Structure
```
{project_name}_ACE/
â”œâ”€â”€ .project                    # Eclipse project file
â”œâ”€â”€ esql/                      # ESQL modules
â”‚   â”œâ”€â”€ modules/               # Core processing modules
â”‚   â”œâ”€â”€ functions/             # Utility functions
â”‚   â”œâ”€â”€ procedures/            # Database procedures
â”‚   â””â”€â”€ enrichment/            # Database enrichment modules
â”œâ”€â”€ transforms/                # Transformation files
â”‚   â””â”€â”€ xsl/                  # XSL transformation files
â”œâ”€â”€ flows/                     # Message flows (from Program 2)
â””â”€â”€ docs/                      # Documentation
    â””â”€â”€ migration_report.md    # This report
```

## Quality Assurance Notes
- All ESQL modules generated using prompt_module.py standards
- Code quality analysis performed on each module
- Business context integration from Confluence documentation
- BizTalk component analysis drives ESQL generation patterns
- Error handling and validation patterns included in all modules
- XSL transformations generated for data transformation requirements
- Database enrichment modules created for business logic requirements

## XSL Transformation Details
- XSL files generated based on BizTalk map analysis and discovered .xsl files
- Compatible with IBM ACE XSLTransform node
- Include proper namespace handling and error management
- Support for complex transformation patterns and business logic

## Enrichment Module Details
- Database lookup modules for company codes, shipments, and document validation
- Conditional execution patterns based on message content
- Proper error handling and fallback mechanisms
- Environment-specific routing and recipient determination

## Support Information
For questions about this migration or the generated code:
1. Review the migration_report.md for detailed analysis
2. Check individual ESQL modules for inline documentation
3. Validate business logic against original BizTalk components
4. Test thoroughly in development environment before deployment
"""
        
        # Save report
        docs_dir = os.path.join(output_dir, "docs")
        os.makedirs(docs_dir, exist_ok=True)
        report_path = os.path.join(docs_dir, "migration_report.md")
        self._save_file(report_path, report_content)
        
        return report_path
    
    def _extract_confluence_context(self, confluence_pdf: str) -> str:
        """Extract business context from Confluence PDF"""
        try:
            import PyPDF2
            
            with open(confluence_pdf, 'rb') as file:
                pdf_reader = PyPDF2.PdfReader(file)
                text = ""
                
                # Extract text from first 5 pages
                for page_num, page in enumerate(pdf_reader.pages[:5]):
                    try:
                        page_text = page.extract_text()
                        if page_text:
                            text += f"\n--- Page {page_num + 1} ---\n"
                            text += page_text + "\n"
                    except Exception as e:
                        print(f"âš ï¸ Error extracting page {page_num + 1}: {e}")
            
            # Clean and format text
            text = re.sub(r'\s+', ' ', text)  # Normalize whitespace
            text = text.strip()
            
            # Return first 3000 characters for context
            return text[:3000] if text else "PDF content extraction yielded no text"
            
        except ImportError:
            print("âš ï¸ PyPDF2 not installed - PDF extraction skipped")
            return "PDF extraction requires PyPDF2 library"
        except Exception as e:
            print(f"âš ï¸ Could not extract PDF content: {e}")
            return f"PDF content extraction failed: {str(e)}"
    
    def _save_file(self, file_path: str, content: str):
        """Save content to file with proper error handling"""
        try:
            os.makedirs(os.path.dirname(file_path), exist_ok=True)
            
            with open(file_path, 'w', encoding='utf-8') as f:
                f.write(content)
            
            self.generated_files.append(file_path)
            print(f"     ðŸ“„ Created: {os.path.basename(file_path)}")
            
        except Exception as e:
            print(f"âš ï¸ Error saving {file_path}: {e}")
    
    def _save_enhancement_report(self, output_dir: str, esql_files: List[str], project_file: str, migration_report: str):
        """Save final enhancement report"""
        
        timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
        
        report = {
            "ace_module_creator": {
                "version": "1.0",
                "timestamp": timestamp,
                "biztalk_analysis": {
                    "components_analyzed": len(self.biztalk_analysis['business_processes']) + 
                                         len(self.biztalk_analysis['data_transformations']) + 
                                         len(self.biztalk_analysis['custom_components']),
                    "esql_modules_generated": len(esql_files),
                    "business_context_used": self.confluence_used,
                    "prompt_module_integration": True
                },
                "generated_files": {
                    "esql_modules": [os.path.basename(f) for f in esql_files],
                    "project_file": os.path.basename(project_file),
                    "migration_report": os.path.basename(migration_report),
                    "total_files": len(self.generated_files)
                },
                "migration_stats": {
                    "biztalk_root_scanned": self.biztalk_analysis['discovery_summary']['biztalk_root'],
                    "total_source_components": self.biztalk_analysis['discovery_summary']['total_components'],
                    "esql_requirements_identified": len(self.biztalk_analysis['esql_requirements'])
                },
                "quality_assurance": {
                    "prompt_module_used": True,
                    "code_quality_analysis": True,
                    "business_context_integration": self.confluence_used,
                    "fallback_mechanisms": True,
                    "error_recovery": True
                }
            }
        }
        
        report_file = os.path.join(output_dir, "ace_module_creation_report.json")
        with open(report_file, 'w', encoding='utf-8') as f:
            json.dump(report, f, indent=2)
        
        self.generated_files.append(report_file)
        print(f"ðŸ“‹ Enhancement report saved: {report_file}")

# Factory function for main.py integration
def create_ace_module_creator():
    """Create ACE Module Creator instance for main.py integration"""
    return ACEModuleCreator()

# Main execution function for UI integration  
def run_ace_module_creator(foundation_dir: str, biztalk_root_dir: str, 
                          confluence_pdf: str = None, groq_api_key: str = None, 
                          groq_model: str = "llama3-70b-8192", config: Dict = None) -> Dict:
    """
    Execute ACE Module Creator with UI inputs
    
    Args:
        foundation_dir: Directory containing Program 2 output
        biztalk_root_dir: Root directory of BizTalk project structure
        confluence_pdf: Path to business specification PDF
        groq_api_key: Groq API key for LLM integration
        groq_model: LLM model to use
        config: Configuration dictionary
        
    Returns:
        Dict with success status and output information
    """
    
    try:
        # Set environment variable if provided
        if groq_api_key:
            os.environ['GROQ_API_KEY'] = groq_api_key
        
        # Create and configure creator
        creator = ACEModuleCreator()
        if config and 'groq_settings' in config:
            creator.config['groq_settings'].update(config['groq_settings'])
        
        # Override model if specified
        creator.config['groq_settings']['model'] = groq_model
        
        # Execute enhancement
        output_dir = creator.enhance(foundation_dir, biztalk_root_dir, confluence_pdf)
        
        return {
            'success': True,
            'output_directory': output_dir,
            'generated_files': len(creator.generated_files),
            'business_context_used': creator.confluence_used,
            'esql_modules_generated': len([f for f in creator.generated_files if f.endswith('.esql')]),
            'biztalk_components_analyzed': creator.biztalk_analysis['discovery_summary']['total_components'] if creator.biztalk_analysis else 0
        }
        
    except Exception as e:
        return {
            'success': False,
            'error': str(e),
            'output_directory': None
        }

def main():
    """Main execution function for command line usage"""
    import sys
    
    if len(sys.argv) < 3:
        print("Usage: python ace_module_creator.py <foundation_dir> <biztalk_root_dir> [confluence_pdf] [output_dir]")
        print("Requirements: GROQ_API_KEY environment variable, prompt_module.py")
        print("Example: python ace_module_creator.py ./ace_foundation 'C:/BizTalk/MyProject' ./business_spec.pdf")
        print("\nFeatures:")
        print("- Comprehensive BizTalk root directory scanning")
        print("- Intelligent component analysis and ESQL generation")
        print("- Integration with prompt_module.py for consistent prompting")
        print("- Eclipse .project file generation")
        print("- Detailed migration reporting and quality analysis")
        return
    
    foundation_dir = sys.argv[1]
    biztalk_root_dir = sys.argv[2]
    confluence_pdf = sys.argv[3] if len(sys.argv) > 3 else None
    output_dir = sys.argv[4] if len(sys.argv) > 4 else None
    
    try:
        print("ðŸš€ Starting ACE Module Creator...")
        print("="*60)
        print(f"Foundation Directory: {foundation_dir}")
        print(f"BizTalk Root: {biztalk_root_dir}")
        print(f"Business Context: {confluence_pdf or 'Not provided'}")
        print(f"Output Directory: {output_dir or 'Auto-generated'}")
        print("="*60)
        
        creator = ACEModuleCreator()
        result = creator.enhance(foundation_dir, biztalk_root_dir, confluence_pdf, output_dir)
        
        print("\n" + "="*60)
        print("ðŸŽ‰ ACE Module Creation Complete!")
        print("="*60)
        print(f"ðŸ“ Output Directory: {result}")
        print(f"ðŸ“„ Generated Files: {len(creator.generated_files)}")
        print(f"ðŸ“‹ Business Context Used: {'Yes' if creator.confluence_used else 'No'}")
        print(f"ðŸ” BizTalk Components Analyzed: {creator.biztalk_analysis['discovery_summary']['total_components']}")
        print(f"âš¡ ESQL Modules Created: {len([f for f in creator.generated_files if f.endswith('.esql')])}")
        print(f"ðŸ”„ XSL Transformations: {len([f for f in creator.generated_files if f.endswith('.xsl')])}")
        print(f"ðŸ“Š Prompt Module Integration: Active")
        print("="*60)
        
        # Display generated files summary
        if creator.generated_files:
            print("\nðŸ“‹ Generated Files Summary:")
            for file_path in creator.generated_files:
                file_type = "ESQL Module" if file_path.endswith('.esql') else \
                           "XSL Transform" if file_path.endswith('.xsl') else \
                           "Project File" if file_path.endswith('.project') else \
                           "Report" if file_path.endswith('.md') else \
                           "Configuration" if file_path.endswith('.json') else "Other"
                
                # Add specific type for enrichment files
                if "enrichment" in file_path.lower() and file_path.endswith('.esql'):
                    file_type = "Enrichment ESQL"
                    
                print(f"  ðŸ“„ {os.path.basename(file_path)} ({file_type})")
        
        print(f"\nâœ… Migration ready for ACE Toolkit import!")
        
    except Exception as e:
        print(f"\nâŒ Error: {e}")
        import traceback
        print("\nðŸ” Detailed Error Information:")
        traceback.print_exc()
        return 1
    
    return 0

if __name__ == "__main__":
    exit(main())